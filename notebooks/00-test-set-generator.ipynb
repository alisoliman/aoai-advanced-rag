{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Generator\n",
    "\n",
    "This Jupyter Notebook demonstrates the process of generating a test set using various tools and libraries. The workflow includes the following steps:\n",
    "\n",
    "1. **Installation of Required Packages**:\n",
    "    - The necessary packages `ragas`, `unstructured`, and `unstructured[pdf]` are installed.\n",
    "\n",
    "2. **Loading Documents**:\n",
    "    - Documents are loaded from a specified directory using `DirectoryLoader` from `langchain_community.document_loaders`.\n",
    "\n",
    "3. **Setting Up Azure OpenAI**:\n",
    "    - Environment variables are loaded from a `.env` file.\n",
    "    - The Azure OpenAI API key and endpoint are set up.\n",
    "    - Instances of `AzureChatOpenAI` and `AzureOpenAIEmbeddings` are created for generating document-level summaries and embeddings.\n",
    "\n",
    "4. **Generating Test Set**:\n",
    "    - A `TestsetGenerator` is created using the previously set up Azure OpenAI instances.\n",
    "    - The test set is generated from the loaded documents with specified distributions for different types of evolutions (`simple`, `reasoning`, `multi_context`).\n",
    "\n",
    "5. **Saving and Viewing the Test Set**:\n",
    "    - The generated test set is converted to a pandas DataFrame for inspection.\n",
    "    - The test set is saved to disk in a specified directory.\n",
    "\n",
    "This notebook provides a comprehensive guide to setting up and generating a test set using Azure OpenAI and other related tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ragas unstructured \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Documents\n",
    "\n",
    "In this step, documents are loaded from a specified directory using the `DirectoryLoader` from `langchain_community.document_loaders`. The loader is configured to use multithreading, handle errors silently, and sample a single document. After loading, the filename metadata is set for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"../data/\", use_multithreading=True, silent_errors=True, sample_size=1\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "for document in documents:\n",
    "    document.metadata[\"filename\"] = document.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "api_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT') \n",
    "api_key=os.getenv('AZURE_OPENAI_API_KEY')\n",
    "llm_deployment_name = os.getenv('AZURE_OPENAI_MODEL_NAME')\n",
    "embedding_deployment_name = os.getenv('AZURE_OPENAI_EMBEDDING_MODEL')\n",
    "api_version = '2024-02-15-preview' # this might change in the future\n",
    "\n",
    "\n",
    "if \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\n",
    "        \"Enter your AzureOpenAI API key: \"\n",
    "    )\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = api_endpoint\n",
    "\n",
    "\n",
    " # Create document-level summaries\n",
    "llm = AzureChatOpenAI(\n",
    "    model=llm_deployment_name,\n",
    "    azure_deployment=llm_deployment_name,\n",
    "    api_version=api_version,\n",
    "    \n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Test Set\n",
    "\n",
    "In this step, a 'TestsetGenerator' is created using the previously set up Azure OpenAI instances. The test set is generated from the loaded documents with specified distributions for different types of evolutions (`simple`, `reasoning`, `multi_context`). The test set generation process includes options to handle exceptions and enable debugging logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=llm, critic_llm=llm, embeddings=embeddings\n",
    ")\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents,\n",
    "    test_size=30,\n",
    "    raise_exceptions=False,\n",
    "    with_debugging_logs=False,\n",
    "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.to_dataset().save_to_disk(\"../data/testset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
